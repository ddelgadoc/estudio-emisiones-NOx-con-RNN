install.packages("rpart")
install.packages("RAM")
install.packages("randomForest")
install.packages("tree")
install.packages("party")
install.packages("partykit")
install.packages("adabag")
install.packages("rmarkdown")
rm(list=ls()) #como clear de matlab
npunt=10;
sensitivityindexmaineffects=rnorm(3,mean=0,sd=1);
sensitivityindexinteractions=rnorm(3,mean=0,sd=1);
impbartmachine1=rnorm(3,mean=0,sd=1);
X1=seq(1,npunt);
X2=seq(1,npunt);
X3=seq(1,npunt);
X1=X1-mean(X1);
X2=X2-mean(X2);
X3=X3-mean(X3);
X1b<-rnorm(npunt^3,mean=3,sd=2);
X2b<-rnorm(npunt^3,mean=3,sd=2);
X3b<-rnorm(npunt^3,mean=3,sd=2);
y=rnorm(npunt^3,mean=3,sd=2);
vectorbetas<-c(1,1,1,3);
sigmaerror<-0;
con=0;
for (i in 1:npunt)
{
for (j in 1:npunt)
{
for (k in 1:npunt)
{
con=con+1;
X1b[con]=X1[i];
X2b[con]=X2[j];
X3b[con]=X3[k];
y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con];
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*(X4b[con]^2)+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X4b[con]+vectorbetas[5]*X1b[con]*X4b[con]+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*((X1b[con]*X2b[con])^2);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X1b[con]*X2b[con];
}
}
}
x1b<-factor(X1b)
x2b<-factor(X2b)
x3b<-factor(X3b)
modbox<-aov(y ~ x1b+x2b+x3b+x1b*x2b+x1b*x3b+x2b*x3b+x1b*x2b*x3b);
anova(modbox)
rm(list=ls()) #como clear de matlab
npunt=10;
sensitivityindexmaineffects=rnorm(3,mean=0,sd=1);
sensitivityindexinteractions=rnorm(3,mean=0,sd=1);
impbartmachine1=rnorm(3,mean=0,sd=1);
X1=seq(1,npunt);
X2=seq(1,npunt);
X3=seq(1,npunt);
X1=X1-mean(X1);
X2=X2-mean(X2);
X3=X3-mean(X3);
X1b<-rnorm(npunt^3,mean=3,sd=2);
X2b<-rnorm(npunt^3,mean=3,sd=2);
X3b<-rnorm(npunt^3,mean=3,sd=2);
y=rnorm(npunt^3,mean=3,sd=2);
vectorbetas<-c(1,1,10,3);
sigmaerror<-0;
con=0;
for (i in 1:npunt)
{
for (j in 1:npunt)
{
for (k in 1:npunt)
{
con=con+1;
X1b[con]=X1[i];
X2b[con]=X2[j];
X3b[con]=X3[k];
y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con];
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*(X4b[con]^2)+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X4b[con]+vectorbetas[5]*X1b[con]*X4b[con]+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*((X1b[con]*X2b[con])^2);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X1b[con]*X2b[con];
}
}
}
x1b<-factor(X1b)
x2b<-factor(X2b)
x3b<-factor(X3b)
modbox<-aov(y ~ x1b+x2b+x3b+x1b*x2b+x1b*x3b+x2b*x3b+x1b*x2b*x3b);
anova(modbox)
rm(list=ls()) #como clear de matlab
npunt=10;
sensitivityindexmaineffects=rnorm(3,mean=0,sd=1);
sensitivityindexinteractions=rnorm(3,mean=0,sd=1);
impbartmachine1=rnorm(3,mean=0,sd=1);
X1=seq(1,npunt);
X2=seq(1,npunt);
X3=seq(1,npunt);
X1=X1-mean(X1);
X2=X2-mean(X2);
X3=X3-mean(X3);
X1b<-rnorm(npunt^3,mean=3,sd=2);
X2b<-rnorm(npunt^3,mean=3,sd=2);
X3b<-rnorm(npunt^3,mean=3,sd=2);
y=rnorm(npunt^3,mean=3,sd=2);
vectorbetas<-c(1,1,10,3);
sigmaerror<-0;
con=0;
for (i in 1:npunt)
{
for (j in 1:npunt)
{
for (k in 1:npunt)
{
con=con+1;
X1b[con]=X1[i];
X2b[con]=X2[j];
X3b[con]=X3[k];
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con];
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*(X4b[con]^2)+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X4b[con]+vectorbetas[5]*X1b[con]*X4b[con]+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*((X1b[con]*X2b[con])^2);
y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X1b[con]*X2b[con];
}
}
}
x1b<-factor(X1b)
x2b<-factor(X2b)
x3b<-factor(X3b)
modbox<-aov(y ~ x1b+x2b+x3b+x1b*x2b+x1b*x3b+x2b*x3b+x1b*x2b*x3b);
anova(modbox)
library("randomForest", lib.loc="~/R/win-library/3.5")
rm(list=ls()) #como clear de matlab
npunt=10;
sensitivityindexmaineffects=rnorm(3,mean=0,sd=1);
sensitivityindexinteractions=rnorm(3,mean=0,sd=1);
impbartmachine1=rnorm(3,mean=0,sd=1);
X1=seq(1,npunt);
X2=seq(1,npunt);
X3=seq(1,npunt);
X1=X1-mean(X1);
X2=X2-mean(X2);
X3=X3-mean(X3);
X1b<-rnorm(npunt^3,mean=3,sd=2);
X2b<-rnorm(npunt^3,mean=3,sd=2);
X3b<-rnorm(npunt^3,mean=3,sd=2);
y=rnorm(npunt^3,mean=3,sd=2);
vectorbetas<-c(1,1,1,3);
sigmaerror<-0;
con=0;
for (i in 1:npunt)
{
for (j in 1:npunt)
{
for (k in 1:npunt)
{
con=con+1;
X1b[con]=X1[i];
X2b[con]=X2[j];
X3b[con]=X3[k];
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con];
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*(X4b[con]^2)+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X4b[con]+vectorbetas[5]*X1b[con]*X4b[con]+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*((X1b[con]*X2b[con])^2);
y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X1b[con]*X2b[con];
}
}
}
x1b<-factor(X1b)
x2b<-factor(X2b)
x3b<-factor(X3b)
modbox<-aov(y ~ x1b+x2b+x3b+x1b*x2b+x1b*x3b+x2b*x3b+x1b*x2b*x3b);
anova(modbox)
library(randomForest)
arbol.rf<-randomForest(y~X1b+X2b+X3b,ntree=500,maxnodes=1000,importance=TRUE)
print(arbol.rf)
varImpPlot(arbol.rf)
importance(arbol.rf)
install.packages("dynaTree")
library("dynaTree", lib.loc="~/R/win-library/3.5")
rm(list=ls()) #como clear de matlab
npunt=10;
sensitivityindexmaineffects=rnorm(3,mean=0,sd=1);
sensitivityindexinteractions=rnorm(3,mean=0,sd=1);
impbartmachine1=rnorm(3,mean=0,sd=1);
X1=seq(1,npunt);
X2=seq(1,npunt);
X3=seq(1,npunt);
X1=X1-mean(X1);
X2=X2-mean(X2);
X3=X3-mean(X3);
X1b<-rnorm(npunt^3,mean=3,sd=2);
X2b<-rnorm(npunt^3,mean=3,sd=2);
X3b<-rnorm(npunt^3,mean=3,sd=2);
y=rnorm(npunt^3,mean=3,sd=2);
vectorbetas<-c(1,1,1,3);
sigmaerror<-0;
con=0;
for (i in 1:npunt)
{
for (j in 1:npunt)
{
for (k in 1:npunt)
{
con=con+1;
X1b[con]=X1[i];
X2b[con]=X2[j];
X3b[con]=X3[k];
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con];
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*(X4b[con]^2)+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X4b[con]+vectorbetas[5]*X1b[con]*X4b[con]+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*((X1b[con]*X2b[con])^2);
y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X1b[con]*X2b[con];
}
}
}
x1b<-factor(X1b)
x2b<-factor(X2b)
x3b<-factor(X3b)
modbox<-aov(y ~ x1b+x2b+x3b+x1b*x2b+x1b*x3b+x2b*x3b+x1b*x2b*x3b);
anova(modbox)
library(randomForest)
arbol.rf<-randomForest(y~X1b+X2b+X3b,ntree=500,maxnodes=1000,importance=TRUE)
print(arbol.rf)
varImpPlot(arbol.rf)
importance(arbol.rf)
xtrain=data.frame(X1b,X2b,X3b)
ytrain=y;
#ahora con el software bayesiano dynatree de Taddy et al (2011) y grmacy et al (2011) mirar en pags 20 y 24 de useres guide de dynatree para funciones relevance y sens
library(dynaTree);
pepe4=dynaTree(xtrain,ytrain,model="constant");
pepe7=sens(pepe4,nns=10000);
pepe8=pepe7$S;
pepe9=pepe7$T
for (i in 1:3)
{
sensitivityindexmaineffects[i]=mean(pepe8[,i]);
sensitivityindexinteractions[i]=mean(pepe8[,i]-pepe9[,i]);
}
sensitivityindexmaineffects
sensitivityindexinteractions
rm(list=ls()) #como clear de matlab
npunt=10;
sensitivityindexmaineffects=rnorm(3,mean=0,sd=1);
sensitivityindexinteractions=rnorm(3,mean=0,sd=1);
impbartmachine1=rnorm(3,mean=0,sd=1);
X1=seq(1,npunt);
X2=seq(1,npunt);
X3=seq(1,npunt);
X1=X1-mean(X1);
X2=X2-mean(X2);
X3=X3-mean(X3);
X1b<-rnorm(npunt^3,mean=3,sd=2);
X2b<-rnorm(npunt^3,mean=3,sd=2);
X3b<-rnorm(npunt^3,mean=3,sd=2);
y=rnorm(npunt^3,mean=3,sd=2);
vectorbetas<-c(1,1,1,3);
sigmaerror<-0;
con=0;
for (i in 1:npunt)
{
for (j in 1:npunt)
{
for (k in 1:npunt)
{
con=con+1;
X1b[con]=X1[i];
X2b[con]=X2[j];
X3b[con]=X3[k];
y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con];
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*(X4b[con]^2)+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X4b[con]+vectorbetas[5]*X1b[con]*X4b[con]+sigmaerror*rnorm(tmues,mean=0,sd=.1);
#y[con]=vectorbetas[1]*(X1b[con]^2)+vectorbetas[2]*(X2b[con]^2)+vectorbetas[3]*(X3b[con]^2)+vectorbetas[4]*((X1b[con]*X2b[con])^2);
#y[con]=vectorbetas[1]*X1b[con]+vectorbetas[2]*X2b[con]+vectorbetas[3]*X3b[con]+vectorbetas[4]*X1b[con]*X2b[con];
}
}
}
x1b<-factor(X1b)
x2b<-factor(X2b)
x3b<-factor(X3b)
modbox<-aov(y ~ x1b+x2b+x3b+x1b*x2b+x1b*x3b+x2b*x3b+x1b*x2b*x3b);
anova(modbox)
library(randomForest)
arbol.rf<-randomForest(y~X1b+X2b+X3b,ntree=500,maxnodes=1000,importance=TRUE)
print(arbol.rf)
varImpPlot(arbol.rf)
importance(arbol.rf)
xtrain=data.frame(X1b,X2b,X3b)
ytrain=y;
#ahora con el software bayesiano dynatree de Taddy et al (2011) y grmacy et al (2011) mirar en pags 20 y 24 de useres guide de dynatree para funciones relevance y sens
library(dynaTree);
pepe4=dynaTree(xtrain,ytrain,model="constant");
pepe7=sens(pepe4,nns=10000);
pepe8=pepe7$S;
pepe9=pepe7$T
for (i in 1:3)
{
sensitivityindexmaineffects[i]=mean(pepe8[,i]);
sensitivityindexinteractions[i]=mean(pepe8[,i]-pepe9[,i]);
}
sensitivityindexmaineffects
sensitivityindexinteractions
x=runif(100000,min=0.max=1)
mean(x^2)
x = runif(100000,min=0.max=1)
x=runif(100000,min=0,max=1)
mean(x^2)
library("tree", lib.loc="~/R/win-library/3.5")
library("tree", lib.loc="~/R/win-library/3.5")
library("rpart", lib.loc="~/R/win-library/3.5")
install.packages("e1071")
library("e1071", lib.loc="~/R/win-library/3.5")
(d1=sqrt((-5.31+5.67)^2))
(d2=sqrt((-5.31+3.32)^2))
install.packages("rriskDistributions")
library("rriskDistributions", lib.loc="~/R/win-library/3.5")
unidim1=rnorm(1000,mean=0,sd=4)
unidim2=rnorm(1000,mean = 5,sd=8)
unidim3=runif(1000,min = 0,max = 1)
y=unidim1*unidim2
mean(y)
sd(y)
y=unidim1+unidim2
mean(y)
sd(y)
y=unidim1+2unidim2
mean(y)
sd(y)
hist(unidim)
unidim1=rnorm(1000,mean=0,sd=4)
unidim2=rnorm(1000,mean = 5,sd=8)
unidim3=runif(1000,min = 0,max = 1)
y=unidim1+2unidim2
mean(y)
sd(y)
y=unidim1+unidim2
mean(y)
sd(y)
install.packages("keras")
x = array(rep(0, 2*3*2), dim = c(2,3,2))
x
dim(x)
x = array(rep(0, 2*3*3), dim = c(2,3,3))
x
dim(x)
library("rpart", lib.loc="~/R/win-library/3.5")
library(readxl)
Data_train <- read_excel("C:/ALMACEN/Documentos/Máster Ing de Organizaón UPM/TFM/Códigos/Análisis estadistico en R/Final_Train_Sin_valores_erroneos.xlsx")
View(Data_train)
library(readr)
data_ok <- read_csv("C:/ALMACEN/Documentos/Máster Ing de Organizaón UPM/TFM/Códigos/Construccion de las redes/Train_estandarizado.csv")
View(data_ok)
library(readr)
data_ok <- read_csv("C:/ALMACEN/Documentos/Máster Ing de Organizaón UPM/TFM/Códigos/Análisis estadistico en R/Train_estandarizado.csv")
View(data_ok)
str(data_ok)
library("forcats", lib.loc="~/R/win-library/3.5")
detach("package:forcats", unload=TRUE)
install.packages("forecast")
library("forecast", lib.loc="~/R/win-library/3.5")
setwd("C:/ALMACEN/Documentos/Máster Ing de Organizaón UPM/TFM/Códigos/Análisis estadistico en R")
library(readxl)
data_train <- read_excel("C:/ALMACEN/Documentos/Máster Ing de Organizaón UPM/TFM/Códigos/Análisis estadistico en R/Final_Train_Sin_valores_erroneos.xlsx")
View(data_train)
View(data_train)
median(data_train$`NOx mass`)
library(readxl)
train <- read_excel("C:/ALMACEN/Documentos/Máster Ing de Organizaón UPM/TFM/Códigos/Análisis estadistico en R/Final_Train_valores erroneos_mediana.xlsx")
View(train)
data_train <- data.frame(train[,5:9],train[,12:13])
mean <- apply(data_train,2,mean)
std <- apply(data_train,2,sd)
data_train <- as.data.frame(scale(data_train, center = mean,scale = std))
View(data_train)
View(data_train)
summary(data_train$NOx.mass)
x = vector() #determinar cantidad de observaciones nulas en NOx despues de la estandarizacion
for (n in data_train$NOx.mass) {
if(n == 0) append(x,n)
}
L = length(x)
L
nor <- function(x) {
return((x - min(x))/(max(x) - min(x)))
}
acel_nor <- lapply(train$Aceleracion,nor)
sobrea_nor <- lapply(train$Sobreace,nor)
data_train_norm <- data.frame(data_train[,1:5],acel_nor,sobrea_nor,train[,11])
acel_nor <- as.data.frame(lapply(train$Aceleracion,nor))
sobrea_nor <- as.data.frame(lapply(train$Sobreace,nor))
data_train_norm <- data.frame(data_train[,1:5],acel_nor,sobrea_nor,train[,11])
View(acel_nor)
acel_nor <- lapply(train$Aceleracion,nor)
sobrea_nor <- lapply(train$Sobreace,nor)
dt <- as.data.frame(acel_nor,sobrea_nor)
dt <- data.frame(acel_nor,sobrea_nor)
View(dt)
View(dt)
View(dt)
acel_nor
dt<- as.data.frame(lapply(train,nor))
dt<- as.data.frame(lapply(train[,12:13],nor))
View(dt)
View(dt)
data_train_norm <- data.frame(data_train[,1:5],dt[],train[,11])
View(data_train_norm)
View(data_train_norm)
min(train$Aceleracion)
max(train$Aceleracion)
View(train)
View(train)
write.csv(data_train_norm,file = "Train_estandarizadoV02.csv",row.names = T)
data_NO <- ts(data_train_norm$NOx.mass,start = 0)
data_a <- ts(data_train_norm$Aceleracion,start = 0)
plot(data_NO,xlab = "Tiempo(s)",xlim = c(0,500),ylim=c(-5,7),col="red",main="Curva de aceleración y caudal de NOx",cex.main=0.9)
lines(data_a,col="blue",type="l")
legend(x=200,y=7.5,legend = c("Caudal de NOx","Aceleración"),fill = c("red","blue"))
